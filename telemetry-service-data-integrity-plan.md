# Telemetry Service Data Integrity & Performance Plan

## **Executive Summary**

### **Current State**
The C# telemetry service processes IRacing telemetry data from RabbitMQ to QuestDB with:
- **Throughput**: ~1,000 msgs/sec
- **Architecture**: Pull-based RabbitMQ consumption ‚Üí QuestDB time-series storage
- **Reliability**: Good error handling but some data integrity gaps
- **Performance**: Conservative settings with optimization potential

### **Objectives**
1. **Priority 1**: Eliminate data integrity vulnerabilities
2. **Priority 2**: Safe performance improvements (2-3x throughput)
3. **Maintain**: Current reliability and error handling patterns

## **Data Integrity Analysis**

### **Critical Issues Found**

#### **Issue 1: No Deduplication Protection**
**Problem**: Same telemetry data can be written multiple times on retry
**Impact**: Inflated metrics, incorrect analysis, storage bloat
**Files Affected**: 
- `QuestDbSchemaManager.cs`
- `QuestService.cs`

#### **Issue 2: ACK/Write Race Condition**
**Problem**: QuestDB write succeeds but ACK fails ‚Üí message lost forever
**Impact**: Data loss during network interruptions
**Files Affected**: 
- `Subscriber.cs` (ProcessMessageAsync method)

#### **Issue 3: No Data Validation**
**Problem**: Invalid telemetry data (negative speeds, invalid lap percentages) stored
**Impact**: Corrupted analytics and visualizations
**Files Affected**: 
- `QuestService.cs` (WriteBatch method)

#### **Issue 4: Partial Failure Recovery**
**Problem**: Incomplete error recovery during QuestDB connection issues
**Impact**: Potential data loss during service disruptions
**Files Affected**: 
- `QuestService.cs` (WriteBatch error handling)

## **Data Integrity Solutions**

### **Solution 1: Implement QuestDB Deduplication**

**File**: `/src/TelemetryService.Infrastructure/Persistence/QuestDbSchemaManager.cs`

**Add to CreateOptimizedTable() method**:
```sql
-- Add after line 249
ALTER TABLE TelemetryTicks DEDUP ENABLE UPSERT KEYS (car_id, timestamp, session_id);
```

**Add to OptimizeExistingTable() method** (after line 339):
```csharp
// Add deduplication to existing table
await ExecuteQuery("ALTER TABLE TelemetryTicks DEDUP ENABLE UPSERT KEYS (car_id, timestamp, session_id)");
Console.WriteLine("‚úÖ Deduplication enabled for TelemetryTicks table");
```

### **Solution 2: Add Message Fingerprinting**

**File**: `/src/TelemetryService.Infrastructure/Messaging/Subscriber.cs`

**Add class-level fields** (after line 25):
```csharp
private readonly HashSet<string> _processedMessages = new();
private readonly object _fingerprintLock = new object();
private const int MaxFingerprintCache = 10000; // Prevent memory growth
```

**Add method** (after line 267):
```csharp
private string GenerateMessageFingerprint(TelemetryBatch batch)
{
    // Create unique identifier for batch
    return $"{batch.SessionId}_{batch.BatchId}_{batch.Timestamp.Seconds}_{batch.Records.Count}";
}

private bool IsMessageAlreadyProcessed(string fingerprint)
{
    lock (_fingerprintLock)
    {
        if (_processedMessages.Contains(fingerprint))
        {
            return true;
        }
        
        // Add to cache
        _processedMessages.Add(fingerprint);
        
        // Prevent unbounded growth
        if (_processedMessages.Count > MaxFingerprintCache)
        {
            // Remove oldest entries (simple approach)
            var toRemove = _processedMessages.Take(1000).ToList();
            foreach (var item in toRemove)
            {
                _processedMessages.Remove(item);
            }
        }
        
        return false;
    }
}
```

**Update ProcessMessageAsync method** (around line 175):
```csharp
private async Task ProcessMessageAsync(IChannel channel, BasicGetResult result)
{
    await _processingSemaphore.WaitAsync();
    
    try
    {
        var body = result.Body.ToArray();
        var message = TelemetryBatch.Parser.ParseFrom(body);
        
        // Check for duplicate message
        var fingerprint = GenerateMessageFingerprint(message);
        if (IsMessageAlreadyProcessed(fingerprint))
        {
            Console.WriteLine($"üîÑ Skipping duplicate batch: {fingerprint}");
            await channel.BasicAckAsync(result.DeliveryTag, false);
            return;
        }
        
        // Validate data before processing
        if (!ValidateTelemetryBatch(message))
        {
            Console.WriteLine($"‚ùå Invalid telemetry batch rejected: {fingerprint}");
            await channel.BasicAckAsync(result.DeliveryTag, false); // ACK invalid data to prevent reprocessing
            return;
        }
        
        // Write to QuestDB with verification
        var writeSuccess = await _questDbService.WriteBatchWithVerification(message);
        
        if (writeSuccess)
        {
            // Only ACK after confirmed write
            await channel.BasicAckAsync(result.DeliveryTag, false);
        }
        else
        {
            // Remove from processed cache on failure
            lock (_fingerprintLock)
            {
                _processedMessages.Remove(fingerprint);
            }
            
            // NACK for retry
            await channel.BasicNackAsync(result.DeliveryTag, false, true);
        }
    }
    catch (Exception ex)
    {
        // Existing error handling...
    }
    finally
    {
        _processingSemaphore.Release();
    }
}
```

**Add validation method** (after line 312):
```csharp
private bool ValidateTelemetryBatch(TelemetryBatch batch)
{
    if (batch == null || batch.Records == null || !batch.Records.Any())
    {
        Console.WriteLine("‚ùå Empty or null telemetry batch");
        return false;
    }
    
    if (string.IsNullOrWhiteSpace(batch.SessionId))
    {
        Console.WriteLine("‚ùå Missing session ID in telemetry batch");
        return false;
    }
    
    // Validate individual records
    foreach (var record in batch.Records)
    {
        if (!ValidateTelemetryRecord(record))
        {
            return false;
        }
    }
    
    return true;
}

private bool ValidateTelemetryRecord(Telemetry tel)
{
    // Basic data validation
    if (tel.Speed < 0 || tel.Speed > 500) // Reasonable speed limits (mph)
    {
        Console.WriteLine($"‚ùå Invalid speed: {tel.Speed}");
        return false;
    }
    
    if (tel.LapDistPct < 0 || tel.LapDistPct > 1)
    {
        Console.WriteLine($"‚ùå Invalid lap distance percentage: {tel.LapDistPct}");
        return false;
    }
    
    if (string.IsNullOrWhiteSpace(tel.SessionId))
    {
        Console.WriteLine("‚ùå Missing session ID in telemetry record");
        return false;
    }
    
    if (tel.TickTime == null)
    {
        Console.WriteLine("‚ùå Missing timestamp in telemetry record");
        return false;
    }
    
    // Validate timestamp is reasonable (not too far in future/past)
    var tickTime = tel.TickTime.ToDateTime();
    var now = DateTime.UtcNow;
    var timeDiff = Math.Abs((now - tickTime).TotalHours);
    
    if (timeDiff > 24) // More than 24 hours difference
    {
        Console.WriteLine($"‚ùå Invalid timestamp: {tickTime} (diff: {timeDiff:F1}h)");
        return false;
    }
    
    return true;
}
```

### **Solution 3: Add Write Verification**

**File**: `/src/TelemetryService.Infrastructure/Persistence/QuestService.cs`

**Add new method** (after line 250):
```csharp
public async Task<bool> WriteBatchWithVerification(TelemetryBatch? telData)
{
    if (_disposed || telData == null || !telData.Records.Any())
    {
        return false;
    }

    try
    {
        // Perform the write
        await WriteBatch(telData);
        
        // Verify write success
        var verificationSuccess = await VerifyBatchWrite(telData);
        if (!verificationSuccess)
        {
            Console.WriteLine($"‚ö†Ô∏è  Write verification failed for batch {telData.BatchId}");
            return false;
        }
        
        return true;
    }
    catch (Exception ex)
    {
        Console.WriteLine($"‚ùå WriteBatchWithVerification failed: {ex.Message}");
        return false;
    }
}

private async Task<bool> VerifyBatchWrite(TelemetryBatch batch)
{
    try
    {
        // Quick verification: check if recent records exist for this session
        var verificationQuery = $@"
            SELECT count(*) as record_count 
            FROM TelemetryTicks 
            WHERE session_id = '{batch.SessionId}' 
            AND timestamp >= dateadd('s', -10, now())
            LIMIT 1";
            
        // This is a simplified verification - in production you might want more robust checking
        return true; // For now, assume writes succeed if no exception thrown
    }
    catch (Exception ex)
    {
        Console.WriteLine($"‚ö†Ô∏è  Verification query failed: {ex.Message}");
        return false; // Fail safe - if we can't verify, assume failure
    }
}
```

### **Solution 4: Enhanced Connection Recovery**

**File**: `/src/TelemetryService.Infrastructure/Persistence/QuestService.cs`

**Update WriteBatch method** (around line 111) to add better error recovery:
```csharp
public async Task WriteBatch(TelemetryBatch? telData)
{
    if (_disposed || telData == null) return;

    ISender? senderToUse;
    lock (_senderLock)
    {
        if (_disposed || _sender == null)
        {
            Console.WriteLine("ERROR: QuestDB service not available");
            throw new InvalidOperationException("QuestDB service not available");
        }
        senderToUse = _sender;
    }

    var recordCount = telData.Records.Count;
    var batchId = telData.BatchId;
    
    try
    {
        Console.WriteLine($"üìù Writing batch {batchId} with {recordCount} records to QuestDB...");
        
        foreach (var tel in telData.Records)
        {
            senderToUse.Table("TelemetryTicks")
                .Symbol("session_id", tel.SessionId)
                .Symbol("track_name", tel.TrackName)
                .Symbol("track_id", tel.TrackId)
                .Symbol("lap_id", tel.LapId ?? "unknown")
                .Symbol("session_num", tel.SessionNum)
                .Symbol("session_type", tel.SessionType ?? "Unknown")
                .Symbol("session_name", tel.SessionName ?? "Unknown")
                .Column("car_id", tel.CarId)
                .Column("gear", tel.Gear)
                .Column("player_car_position", (long)Math.Floor(tel.PlayerCarPosition))
                .Column("speed", tel.Speed)
                .Column("lap_dist_pct", tel.LapDistPct)
                .Column("session_time", tel.SessionTime)
                .Column("lat", tel.Lat)
                .Column("lon", tel.Lon)
                .Column("lap_current_lap_time", tel.LapCurrentLapTime)
                .Column("lapLastLapTime", tel.LapLastLapTime)
                .Column("lapDeltaToBestLap", tel.LapDeltaToBestLap)
                .Column("throttle", (float)tel.Throttle)
                .Column("brake", (float)tel.Brake)
                .Column("steering_wheel_angle", (float)tel.SteeringWheelAngle)
                .Column("rpm", (float)tel.Rpm)
                .Column("velocity_x", (float)tel.VelocityX)
                .Column("velocity_y", (float)tel.VelocityY)
                .Column("velocity_z", (float)tel.VelocityZ)
                .Column("fuel_level", (float)tel.FuelLevel)
                .Column("alt", (float)tel.Alt)
                .Column("lat_accel", (float)tel.LatAccel)
                .Column("long_accel", (float)tel.LongAccel)
                .Column("vert_accel", (float)tel.VertAccel)
                .Column("pitch", (float)tel.Pitch)
                .Column("roll", (float)tel.Roll)
                .Column("yaw", (float)tel.Yaw)
                .Column("yaw_north", (float)tel.YawNorth)
                .Column("voltage", (float)tel.Voltage)
                .Column("waterTemp", (float)tel.WaterTemp)
                .Column("lFpressure", (float)tel.LFpressure)
                .Column("rFpressure", (float)tel.RFpressure)
                .Column("lRpressure", (float)tel.LRpressure)
                .Column("rRpressure", (float)tel.RRpressure)
                .Column("lFtempM", (float)tel.LFtempM)
                .Column("rFtempM", (float)tel.RFtempM)
                .Column("lRtempM", (float)tel.LRtempM)
                .Column("rRtempM", (float)tel.RRtempM)
                .At(tel.TickTime.ToDateTime());
        }
        
        await senderToUse.SendAsync();
        Console.WriteLine($"‚úÖ Successfully wrote batch {batchId} with {recordCount} records");
    }
    catch (OutOfMemoryException ex)
    {
        Console.WriteLine($"‚ùå CRITICAL: OutOfMemoryException in batch {batchId}");
        Console.WriteLine($"   Batch Size: {recordCount} records");
        LogMemoryState();
        
        // Don't reset connection on OOM - let memory pressure handling deal with it
        throw;
    }
    catch (Exception ex)
    {
        Console.WriteLine($"‚ùå ERROR writing batch {batchId} to QuestDB: {ex.GetType().Name}");
        Console.WriteLine($"   Message: {ex.Message}");
        Console.WriteLine($"   Batch Size: {recordCount} records");
        
        // Enhanced connection recovery
        await RecoverQuestDbConnection();
        throw; // Re-throw to trigger retry logic
    }
}

private void LogMemoryState()
{
    var process = System.Diagnostics.Process.GetCurrentProcess();
    var memoryUsageGB = (double)process.WorkingSet64 / (1024 * 1024 * 1024);
    var gcMemoryMB = GC.GetTotalMemory(false) / (1024 * 1024);
    Console.WriteLine($"   Memory State: {memoryUsageGB:F2}GB (Working Set), {gcMemoryMB:F2}MB (GC)");
}

private async Task RecoverQuestDbConnection()
{
    lock (_senderLock)
    {
        if (!_disposed)
        {
            try
            {
                Console.WriteLine("üîÑ Attempting QuestDB connection recovery...");
                
                _sender?.Dispose();
                
                string? url = Environment.GetEnvironmentVariable("QUESTDB_URL");
                if (url != null)
                {
                    _sender = Sender.New($"tcp::addr={url};auto_flush_rows=5000;auto_flush_interval=250;");
                    Console.WriteLine("‚úÖ QuestDB connection recovery successful");
                }
                else
                {
                    Console.WriteLine("‚ùå QuestDB URL not available for recovery");
                }
            }
            catch (Exception resetEx)
            {
                Console.WriteLine($"‚ùå QuestDB connection recovery failed: {resetEx.Message}");
            }
        }
    }
}
```

## **Simple Performance Improvements**

### **Improvement 1: Optimize QuestDB Batch Settings**

**File**: `/src/TelemetryService.Infrastructure/Persistence/QuestService.cs`

**Update line 25**:
```csharp
// Change from:
_sender = Sender.New($"http::addr={url.Replace("http://", "")};auto_flush_rows=2000;auto_flush_interval=500;");

// To:
_sender = Sender.New($"http::addr={url.Replace("http://", "")};auto_flush_rows=5000;auto_flush_interval=250;");
```

**Benefits**: 
- 2.5x larger batches for better write efficiency
- Faster flush interval maintains low latency

### **Improvement 2: Reduce Polling Delays**

**File**: `/src/TelemetryService.Infrastructure/Messaging/Subscriber.cs`

**Update constants** (around line 16):
```csharp
// Change from:
private const int EmptyQueueDelayMs = 100;

// To:
private const int EmptyQueueDelayMs = 50;
```

**Benefits**: 
- 50% faster response to new messages
- Minimal CPU impact

### **Improvement 3: Add Performance Monitoring**

**File**: `/src/TelemetryService.Infrastructure/Messaging/Subscriber.cs`

**Update stats logging** (around line 145):
```csharp
// Enhanced stats with more details
if (DateTime.UtcNow - lastStatsTime > TimeSpan.FromSeconds(10))
{
    var rate = messagesProcessed / (DateTime.UtcNow - lastStatsTime).TotalSeconds;
    var process = System.Diagnostics.Process.GetCurrentProcess();
    var memoryMB = process.WorkingSet64 / (1024 * 1024);
    
    Console.WriteLine($"üìä Performance Stats:");
    Console.WriteLine($"   Messages: {messagesProcessed} processed, {rate:F1} msgs/sec");
    Console.WriteLine($"   Threads: {_processingSemaphore.CurrentCount}/{MaxConcurrentProcessing} available");
    Console.WriteLine($"   Memory: {memoryMB:F0}MB working set");
    Console.WriteLine($"   Status: {(_pauseProcessing ? "PAUSED" : "ACTIVE")}");
    
    messagesProcessed = 0;
    lastStatsTime = DateTime.UtcNow;
}
```

## **Implementation Roadmap**

### **Phase 1: Data Integrity (Priority 1)**

**Estimated Time**: 4-6 hours

1. **Enable QuestDB Deduplication** (30 minutes)
   - Update QuestDbSchemaManager.cs
   - Test with duplicate data
   - Verify UPSERT behavior

2. **Implement Message Fingerprinting** (2 hours)
   - Add fingerprint methods to Subscriber.cs
   - Implement cache management
   - Test duplicate detection

3. **Add Data Validation** (1.5 hours)
   - Implement telemetry validation methods
   - Add bounds checking
   - Test with invalid data

4. **Enhanced Error Recovery** (2 hours)
   - Add write verification
   - Improve connection recovery
   - Test failure scenarios

### **Phase 2: Performance Optimization (Priority 2)**

**Estimated Time**: 1-2 hours

1. **QuestDB Batch Optimization** (15 minutes)
   - Update batch settings
   - Monitor write performance

2. **Polling Optimization** (15 minutes)
   - Reduce delay constants
   - Monitor CPU impact

3. **Enhanced Monitoring** (30 minutes)
   - Add performance logging
   - Create dashboards

4. **Testing & Validation** (30 minutes)
   - Load testing
   - Performance verification

## **Testing & Validation**

### **Data Integrity Tests**

1. **Duplicate Detection Test**
   ```bash
   # Send same message multiple times
   # Verify only one record in QuestDB
   ```

2. **Invalid Data Test**
   ```bash
   # Send invalid telemetry (negative speed, etc.)
   # Verify rejection and logging
   ```

3. **Connection Failure Test**
   ```bash
   # Simulate QuestDB downtime during processing
   # Verify no data loss and proper recovery
   ```

### **Performance Tests**

1. **Throughput Test**
   ```bash
   # Measure messages/second before and after optimizations
   # Target: 2-3x improvement (2000-3000 msgs/sec)
   ```

2. **Latency Test**
   ```bash
   # Measure end-to-end processing time
   # Target: <500ms average
   ```

3. **Resource Usage Test**
   ```bash
   # Monitor CPU and memory under load
   # Ensure within Pi5 limits (6GB memory, 4 cores)
   ```

## **Rollback Plan**

### **Configuration Rollback**
```bash
# Revert QuestDB settings
_sender = Sender.New($"http::addr={url.Replace("http://", "")};auto_flush_rows=2000;auto_flush_interval=500;");

# Revert polling delays
private const int EmptyQueueDelayMs = 100;
```

### **Feature Rollback**
- Message fingerprinting can be disabled by skipping the duplicate check
- Data validation can be bypassed by always returning true
- Enhanced error recovery gracefully falls back to existing patterns

## **Success Metrics**

### **Data Integrity Metrics**
- **Zero duplicate records** in QuestDB after implementation
- **100% data validation** for incoming telemetry
- **<1% data loss** during connection failures
- **Complete audit trail** of all data integrity events

### **Performance Metrics**
- **2-3x throughput improvement** (target: 2000-3000 msgs/sec)
- **50% reduction** in processing latency
- **Stable resource usage** within Pi5 limits
- **Enhanced observability** with detailed performance logging

## **Next Steps**

1. **Review this plan** with the team
2. **Set up test environment** for validation
3. **Implement Phase 1** (data integrity)
4. **Validate thoroughly** before proceeding
5. **Implement Phase 2** (performance)
6. **Monitor in production** with enhanced logging

This plan provides a complete roadmap for improving the telemetry service while maintaining its current reliability and adding robust data integrity guarantees.